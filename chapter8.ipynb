{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import string\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanInput(input):\n",
    "    input = re.sub('\\n+', \" \", input).lower()\n",
    "    input = re.sub('\\[[0-9]*\\]', \"\", input)\n",
    "    input = re.sub(' +', \" \", input)\n",
    "    input = bytes(input, \"UTF-8\")\n",
    "    input = input.decode(\"ascii\", \"ignore\")\n",
    "    cleanInput = []\n",
    "    input = input.split(' ')\n",
    "    for item in input:\n",
    "        item = item.strip(string.punctuation)\n",
    "        if len(item) > 1 or (item.lower() == 'a' or item.lower() == 'i'):\n",
    "            cleanInput.append(item)\n",
    "    return cleanInput\n",
    "\n",
    "def ngrams(input, n):\n",
    "    input = cleanInput(input)\n",
    "    output = {}\n",
    "    for i in range(len(input)-n+1):\n",
    "        ngramTemp = \" \".join(input[i:i+n])\n",
    "        if ngramTemp not in output:\n",
    "            output[ngramTemp] = 0\n",
    "        output[ngramTemp] += 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content= str(urlopen(\"http://pythonscraping.com/files/inaugurationSpeech.txt\").read(), 'utf-8')\n",
    "ngrams = ngrams(content, 2)\n",
    "sortedNGrams = sorted(ngrams.items(), key = operator.itemgetter(1), reverse=True)\n",
    "print(sortedNGrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isCommon(ngram):\n",
    "    commonWords = [\"the\", \"be\", \"and\", \"of\", \"a\", \"in\", \"to\", \"have\", \"it\",\n",
    "                     \"i\", \"that\", \"for\", \"you\", \"he\", \"with\", \"on\", \"do\", \"say\",\n",
    "                        \"this\", \"they\", \"is\", \"an\", \"at\", \"but\",\"we\", \"his\", \"from\",\n",
    "                        \"that\", \"not\", \"by\", \"she\", \"or\", \"as\", \"what\", \"go\", \"their\",\n",
    "                        \"can\", \"who\", \"get\", \"if\", \"would\", \"her\", \"all\", \"my\", \"make\",\n",
    "                        \"about\", \"know\", \"will\", \"as\", \"up\", \"one\", \"time\", \"has\", \"been\",\n",
    "                        \"there\", \"year\", \"so\", \"think\", \"when\", \"which\", \"them\", \"some\",\n",
    "                        \"me\", \"people\", \"take\", \"out\", \"into\", \"just\", \"see\", \"him\", \"your\",\n",
    "                        \"come\", \"could\", \"now\", \"than\", \"like\", \"other\", \"how\", \"then\", \"its\",\n",
    "                        \"our\", \"two\", \"more\", \"these\", \"want\", \"way\", \"look\", \"first\", \"also\"]\n",
    "    for word in ngram:\n",
    "        if word in commonWords:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def ngrams(input, n):\n",
    "    input = cleanInput(input)\n",
    "    output = {}\n",
    "    for i in range(len(input)-n+1):\n",
    "        ngramTemp = \" \".join(input[i:i+n])\n",
    "        if isCommon(ngramTemp.split()):\n",
    "            continue\n",
    "        if ngramTemp not in output:\n",
    "            output[ngramTemp] = 0\n",
    "        output[ngramTemp] += 1\n",
    "    return output\n",
    "\n",
    "ngrams = ngrams(content, 2)\n",
    "sortedNGrams = sorted(ngrams.items(), key = operator.itemgetter(1), reverse=True)\n",
    "print(sortedNGrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def wordListSum(wordList):\n",
    "    sum = 0\n",
    "    for word, value in wordList.items():\n",
    "        sum += value\n",
    "    return sum\n",
    "\n",
    "def retrieveRandomWord(wordList):\n",
    "    randIndex = randint(1, wordListSum(wordList))\n",
    "    for word, value in wordList.items():\n",
    "        randIndex -= value\n",
    "        if randIndex <= 0:\n",
    "            return word\n",
    "        \n",
    "def buildWordDict(text):\n",
    "    text = cleanInput(text)\n",
    "    wordDict = {}\n",
    "    for i in range(1, len(text)):\n",
    "        if text[i-1] not in wordDict:\n",
    "            wordDict[text[i-1]] = {}\n",
    "        if text[i] not in wordDict[text[i-1]]:\n",
    "            wordDict[text[i-1]][text[i]] = 0\n",
    "        wordDict[text[i-1]][text[i]] += 1\n",
    "    return wordDict\n",
    "\n",
    "text = str(urlopen(\"http://pythonscraping.com/files/inaugurationSpeech.txt\").read(), 'utf-8')\n",
    "wordDict = buildWordDict(text)\n",
    "\n",
    "length = 100\n",
    "chain = \"\"\n",
    "currentWord = \"i\"\n",
    "for i in range(0, length):\n",
    "    chain += currentWord + \" \"\n",
    "    currentWord = retrieveRandomWord(wordDict[currentWord])\n",
    "\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "content= str(urlopen(\"http://pythonscraping.com/files/inaugurationSpeech.txt\").read(), 'utf-8')\n",
    "from nltk import FreqDist\n",
    "fdist = FreqDist(word_tokenize(content, language='english', preserve_line=False))\n",
    "fdist.plot(50, cumulative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import bigrams\n",
    "bigrams = bigrams(word_tokenize(content, language='english', preserve_line=False))\n",
    "bigramsDist = FreqDist(bigrams)\n",
    "bigramsDist.plot(50, cumulative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import trigrams\n",
    "trigrams = trigrams(word_tokenize(content, language='english', preserve_line=False))\n",
    "trigramsDist = FreqDist(trigrams)\n",
    "trigramsDist.plot(50, cumulative=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Text(word_tokenize(\"Strange women lying in ponds distributing swords is no basis for a system of government. Supreme executive power derives from a mandate from the masses, not from some farcical aquatic ceremony.\", language='english', preserve_line=False))\n",
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(\"Google is one of the best companies in the world. I constantly google myself to see what I'm up to.\", language='english')\n",
    "nouns = ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "for sentence in sentences:\n",
    "    if \"google\" in sentence.lower():\n",
    "        taggedWords = pos_tag(word_tokenize(sentence, language='english', preserve_line=False))\n",
    "        for word in taggedWords:\n",
    "            if word[0].lower() == \"google\" and word[1] in nouns:\n",
    "                print(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
